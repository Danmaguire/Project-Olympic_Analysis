{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ages of Athletes \n",
    "This is the notebook for getting the information on the ages of each individual athlete. As it stands there are 2680 athletes out of 25825 that we cannot get the age for. We have also not decided if we are going to actually use the age field yet so it might not be nessecary to get the remaining ages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "from bs4 import BeautifulSoup\n",
    "import webbrowser\n",
    "import urllib.request\n",
    "from lxml import html\n",
    "import zipfile\n",
    "import re\n",
    "import string\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the file exists\n",
    "if not os.path.exists(r\"..\\..\\data\\prep\\Games\\Games-500.csv\" ):\n",
    "    print(\"Missing dataset file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"..\\..\\data\\prep\\Games\\Games-500.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to scrape the Olympic Website\n",
    "Each athlete that has played in the olympic games has there own individual page on the olympic website. On these pages are some perosnal details as well as games history. On every page is the athletees DOB this is what we want from each athlete when we scrape. The function below goes to the area of the html page that contains the DOB, it is the same in every page and scrapes and returns the year of birth. Each atheltes page is this url https://www.olympic.org/{} with the ahtletes name on the end the probelm is sometimes athletes have up to 5 names and the names used on the url are a mix of these not always consitent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to get the age of an olympian from the olympics website \n",
    "def getAge(name):\n",
    "    \n",
    "    # The basic url without the name of athlete at the end \n",
    "    url = \"https://www.olympic.org/{}\".format(name)\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            page = response.read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        \n",
    "        #cfinds all the text-box on the html page\n",
    "        result = soup.find_all(\"div\", {\"class\":\"text-box\"})\n",
    "        #the DOB is always in the 4th one on the pages\n",
    "        print(result[3].text)\n",
    "        \n",
    "        # the rest of the code breaks up the text box extracting only the DOB\n",
    "        string = result[3].text\n",
    "        string = string.replace(\"\\r\", \"\")\n",
    "        string  = string.replace(\"\\n\", \" \")\n",
    "        if(string[1] == 'B'):\n",
    "            string = string[14:18]\n",
    "        elif(string[1] == 'L'):\n",
    "            string = string[15:19]\n",
    "        else:\n",
    "            string = None\n",
    "        return string\n",
    "    except:\n",
    "        print (\"ERROR - \"+url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple for loop if the city is in the same country as the athlete is from set true to Home_Adv else false\n",
    "for x in range(len(df)):\n",
    "    index = df.iloc[x].name \n",
    "    year_of_games = df['Year'].iloc[x]\n",
    "    name = df['Ath_Name'].iloc[x]\n",
    "    \n",
    "    print(\"Row number: \", index)\n",
    "    namL = name.split(',')\n",
    "    \n",
    "    if(len(namL) > 1):\n",
    "        name = name.lower()\n",
    "        name = name.replace('รถ', 'o')\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        namL = name.split(',')\n",
    "\n",
    "        firstname = namL[1].translate(translator)\n",
    "        lastname = namL[0].translate(translator)\n",
    "\n",
    "        comb_name = firstname + \" \" +  lastname\n",
    "        comb_name = comb_name.split()\n",
    "\n",
    "        fullname = '-'.join(comb_name)\n",
    "        fullname = fullname.lower()\n",
    "\n",
    "    try:\n",
    "        age = int(getAge(fullname))\n",
    "        df.set_value(index, 'Age', year_of_games - age)\n",
    "    except: \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(r\"..\\..\\data\\prep\\Games\\Games-550.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
